## Hi there ðŸ‘‹

# Zhiyu Yang

**Email:** kelvin.yangzhiyu@outlook.com  
**Location:** Beijing, China

[GitHub](https://github.com/KevinCL16) | [Google Scholar](https://scholar.google.com/citations?user=KLbbYf0AAAAJ&hl=en)

## Education

**M.Eng. in Computer Science and Technology**  
*Beijing Language and Culture University*  
*September 2021 - July 2024*  

**B.Eng. in Computer Science and Technology**  
*Sichuan University*  
*September 2017 - July 2021*  

## Research Publications

### [MatPlotAgent](https://arxiv.org/abs/2402.11453) - ACL 2024 Findings (First Author)
- **Authors:** Zhiyu Yang, Zihan Zhou, Shuo Wang, Xin Cong, Xu Han, Yukun Yan, Zhenghao Liu, Zhixing Tan, Pengyuan Liu, Dong Yu, Zhiyuan Liu, Xiaodong Shi, Maosong Sun.
- **Summary:** Introduced MatPlotBench for automatic evaluation of AI methods for scientific data visualization. Proposed MatPlotAgent, a framework using visual feedback to enhance LLM performance.
- **Contribution:** Designed the framework and evaluation method, conducted experiments, and curated data for MatPlotBench.

### [UltraLink](https://arxiv.org/abs/2402.04588) - ACL 2024 (Fifth Author)
- **Authors:** Haoyu Wang, Shuo Wang, Yukun Yan, Xujia Wang, Zhiyu Yang, Yuzhuang Xu, Zhenghao Liu, Liner Yang, Ning Ding, Xu Han, Zhiyuan Liu, Maosong Sun.
- **Summary:** Developed a multilingual SFT dataset with language-specific and language-agnostic subsets using Wikipedia and translation methods.
- **Contribution:** Concretized the paper's idea, designed initial prompt templates for data synthesis, and revised the paper.

### Enhancing Free-Form Table Question Answering Models by Distilling Relevant-Cell-Based Rationales - CCL 2024 (First Author)
- **Authors:** Zhiyu Yang, Shuo Wang, Yukun Yan, Pengyuan Liu, Dong Yu.
- **Summary:** Proposed a knowledge distillation method for table QA tasks using relevant-cell-based rationales, achieving SOTA results on the FeTaQA benchmark.
- **Contribution:** Developed the distillation method, conducted experiments, and authored the paper.

## Research Experience

**Research Intern**  
*THUNLP, Tsinghua University*  
*April 2023 - Present*  
- Conducting NLP research under the supervision of Shuo Wang, Ph.D.
- Developed LLM agents for scientific visualization and multilingual SFT data.
- Leading a team to devise an agent framework for processing long context inputs.

## Projects

### SemEval 2022 Task 7 (Rank: 9) - 2021
- Explored various pre-trained language models for understanding the plausibility of implicit and underspecified texts.
- Fine-tuned Facebook AIâ€™s MUPPET model for optimal performance.

### Garbage Image Classification Based on Deep Neural Networks - 2021
- Proposed a novel image classification deep neural network architecture.
- Achieved superior performance compared to mainstream models on a Huawei Cloud Competition dataset.

## Skills

### Languages
- **Mandarin:** Native
- **English:** Fluent (IELTS Overall Band 8.0, Reading: 9, Listening: 9, Writing: 7.5, Speaking: 7)

### Programming Languages
- Python, C++, Java

### Tools and Frameworks
- PyTorch, Huggingface, PyG, Keras, TensorFlow 2, Linux, Android Studio, vllm, LangChain, Matplotlib, Numpy, Pandas

### Deep Learning
- Convolutional Neural Networks, Pre-trained NLU and NLG models, LLMs


<!--
**KevinCL16/KevinCL16** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ðŸ”­ Iâ€™m currently working on ...
- ðŸŒ± Iâ€™m currently learning ...
- ðŸ‘¯ Iâ€™m looking to collaborate on ...
- ðŸ¤” Iâ€™m looking for help with ...
- ðŸ’¬ Ask me about ...
- ðŸ“« How to reach me: ...
- ðŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->
