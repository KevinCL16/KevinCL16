## Hi there üëã
**I am seeking a Ph.D. position!** 
**Incoming RA @ Singapore Management University**
**Prev. Research Intern @ THUNLP**
**Excited for the future of AI, want to be a part of it!**

# Zhiyu Yang üèéÔ∏è‚öΩü§ñ

**Email:** kelvin.yangzhiyu@outlook.com  
**Hometown:** Chengdu, China

[GitHub](https://github.com/KevinCL16) | [Google Scholar](https://scholar.google.com/citations?user=KLbbYf0AAAAJ&hl=en)

## Education

**M.Eng. in Computer Science and Technology**  
*Beijing Language and Culture University*  
*September 2021 - July 2024*  

**B.Eng. in Computer Science and Technology**  
*Sichuan University*  
*September 2017 - July 2021*  

## Research Experience

**Research Intern**  
*THUNLP, Tsinghua University*  
*April 2023 - July 2024*  
- Conducting NLP research under the supervision of [Shuo Wang](https://scholar.google.com/citations?user=5vm5yAMAAAAJ&hl=en), Ph.D.
- Distilled table reasoning skills from LLMs to small PLMs.
- Developed LLM agents for scientific data visualization.
- Curated multilingual SFT data.
- Participated in devising an agent framework for processing long context inputs.

## Research Publications

### [MatPlotAgent](https://arxiv.org/abs/2402.11453) - ACL 2024 Findings (First Author)
- **Authors:** Zhiyu Yang, Zihan Zhou, Shuo Wang, Xin Cong, Xu Han, Yukun Yan, Zhenghao Liu, Zhixing Tan, Pengyuan Liu, Dong Yu, Zhiyuan Liu, Xiaodong Shi, Maosong Sun.
- **Summary:** Introduced MatPlotBench for automatic evaluation of AI methods for scientific data visualization. Proposed MatPlotAgent, a framework using visual feedback to enhance LLM performance.
- **Contribution:** Designed the agent framework and evaluation method, conducted experiments, and curated data for MatPlotBench.

### [UltraLink](https://arxiv.org/abs/2402.04588) - ACL 2024 (Fifth Author)
- **Authors:** Haoyu Wang, Shuo Wang, Yukun Yan, Xujia Wang, Zhiyu Yang, Yuzhuang Xu, Zhenghao Liu, Liner Yang, Ning Ding, Xu Han, Zhiyuan Liu, Maosong Sun.
- **Summary:** Developed a multilingual SFT dataset with language-specific and language-agnostic subsets using knowledge-enhanced data augmentation methods with Wikipedia as knowledge source.
- **Contribution:** Concretized the paper's idea, designed initial prompt templates for data synthesis, and revised the paper.

### Enhancing Free-Form Table Question Answering Models by Distilling Relevant-Cell-Based Rationales - CCL 2024 (First Author)
- **Authors:** Zhiyu Yang, Shuo Wang, Yukun Yan, Pengyuan Liu, Dong Yu.
- **Summary:** Proposed a knowledge distillation method for table QA tasks using relevant-cell-based rationales, achieving SOTA results on the FeTaQA benchmark.
- **Contribution:** Developed the distillation method, conducted experiments, and authored the paper.

## Projects

### SemEval 2022 Task 7 (Rank: 9) - 2021
- Explored various pre-trained language models for understanding the plausibility of implicit and underspecified texts.
- Fine-tuned Facebook AI‚Äôs MUPPET model for optimal performance.

### Garbage Image Classification Based on Deep Neural Networks - 2021
- Proposed a novel garbage classification deep neural network architecture.
- Achieved superior performance compared to mainstream models on a Huawei Cloud Garbage Classification Competition dataset.

## Skills

### Languages
- **Mandarin:** Native
- **English:** Fluent (IELTS Overall Band 8.0, Reading: 9, Listening: 9, Writing: 7.5, Speaking: 7)

### Programming Languages
- Python, C++, Java

### Tools and Frameworks
- PyTorch, Huggingface, PyG, Keras, TensorFlow 2, Linux, Android Studio, vLLM, Matplotlib, Numpy, Pandas

### Deep Learning
- Convolutional Neural Networks, Pre-trained NLU and NLG models, LLMs


<!--
**KevinCL16/KevinCL16** is a ‚ú® _special_ ‚ú® repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- üî≠ I‚Äôm currently working on ...
- üå± I‚Äôm currently learning ...
- üëØ I‚Äôm looking to collaborate on ...
- ü§î I‚Äôm looking for help with ...
- üí¨ Ask me about ...
- üì´ How to reach me: ...
- üòÑ Pronouns: ...
- ‚ö° Fun fact: ...
-->
